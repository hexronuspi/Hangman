{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class HangmanPlayer:\n",
    "    def __init__(self, word, model, lives=6):\n",
    "        self.original_word = word\n",
    "        self.full_word = [ord(i)-97 for i in word]\n",
    "        self.letters_guessed = set([])\n",
    "        self.letters_remaining = set(self.full_word)\n",
    "        self.lives_left = lives\n",
    "        self.obscured_words_seen = []\n",
    "        self.letters_previously_guessed = []\n",
    "        self.guesses = []\n",
    "        self.correct_responses = []\n",
    "        self.z = model\n",
    "        return\n",
    "\n",
    "    def encode_obscured_word(self):\n",
    "        obscured_word = np.zeros((len(self.full_word), 29), dtype=np.float32)\n",
    "        guessed_mask = np.array([i in self.letters_guessed for i in self.full_word], dtype=np.bool_)\n",
    "        obscured_word[np.arange(len(self.full_word)), np.where(guessed_mask, self.full_word, 26)] = 1\n",
    "        return obscured_word\n",
    "\n",
    "    def encode_guess(self, guess):\n",
    "        encoded_guess = np.zeros(26, dtype=np.float32)\n",
    "        encoded_guess[guess] = 1\n",
    "        return(encoded_guess)\n",
    "\n",
    "    def encode_previous_guesses(self):\n",
    "        guess = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_guessed:\n",
    "            guess[i] = 1\n",
    "        return(guess)\n",
    "\n",
    "    def encode_correct_responses(self):\n",
    "        response = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_remaining:\n",
    "            response[i] = 1.0\n",
    "        response /= response.sum()\n",
    "        return(response)\n",
    "\n",
    "    def store_guess_and_result(self, guess):\n",
    "        self.obscured_words_seen.append(self.encode_obscured_word())\n",
    "        self.letters_previously_guessed.append(self.encode_previous_guesses())\n",
    "\n",
    "        self.guesses.append(guess)\n",
    "        self.letters_guessed.add(guess)\n",
    "\n",
    "        correct_responses = self.encode_correct_responses()\n",
    "        self.correct_responses.append(correct_responses)\n",
    "\n",
    "        if guess in self.letters_remaining:\n",
    "            self.letters_remaining.remove(guess)\n",
    "\n",
    "        if self.correct_responses[-1][guess] < 0.00001:\n",
    "            self.lives_left -= 1\n",
    "        return\n",
    "\n",
    "    def run(self):\n",
    "        while self.lives_left > 0 and len(self.letters_remaining) > 0:\n",
    "            obscured_word_tensor = torch.tensor(self.encode_obscured_word(), dtype=torch.float32).to(device)\n",
    "            previous_guesses_tensor = torch.tensor(self.encode_previous_guesses(), dtype=torch.float32).to(device)\n",
    "\n",
    "            obscured_word_tensor = obscured_word_tensor.unsqueeze(0)\n",
    "            previous_guesses_tensor = previous_guesses_tensor.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.z(obscured_word_tensor, previous_guesses_tensor)\n",
    "                guess = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "            self.store_guess_and_result(guess)\n",
    "\n",
    "        return (np.array(self.obscured_words_seen),\n",
    "                np.array(self.letters_previously_guessed),\n",
    "                np.array(self.correct_responses))\n",
    "\n",
    "    def show_words_seen(self):\n",
    "        for word in self.obscured_words_seen:\n",
    "            print(''.join([chr(i + 97) if i != 26 else ' ' for i in word.argmax(axis=1)]))\n",
    "\n",
    "    def show_guesses(self):\n",
    "        for guess in self.guesses:\n",
    "            print(chr(guess + 97))\n",
    "\n",
    "    def play_by_play(self):\n",
    "        print('Hidden word was \"{}\"'.format(self.original_word))\n",
    "        for i in range(len(self.guesses)):\n",
    "            word_seen = ''.join([chr(i + 97) if i != 26 else ' ' for i in self.obscured_words_seen[i].argmax(axis=1)])\n",
    "            print('Guessed {} after seeing \"{}\"'.format(chr(self.guesses[i] + 97),\n",
    "                                                        word_seen))\n",
    "\n",
    "    def evaluate_performance(self):\n",
    "        ended_in_success = self.lives_left > 0\n",
    "        letters_in_word = set([i for i in self.original_word])\n",
    "        correct_guesses = len(letters_in_word) - len(self.letters_remaining)\n",
    "        incorrect_guesses = len(self.guesses) - correct_guesses\n",
    "        return(ended_in_success, correct_guesses, incorrect_guesses, letters_in_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open('/content/words_250000_train.txt', 'r') as f:\n",
    "    words = [line.strip() for line in f.readlines()]\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(words)\n",
    "\n",
    "train_val_split_idx = int(len(words) * 0.8)\n",
    "print('Training with {} WordNet words'.format(train_val_split_idx))\n",
    "\n",
    "MAX_NUM_INPUTS = max([len(i) for i in words[:train_val_split_idx]])\n",
    "EPOCH_SIZE = train_val_split_idx\n",
    "NUM_EPOCHS = 3\n",
    "NUM_CLASSES = 26\n",
    "BATCH_SIZE = np.array([len(i) for i in words[:train_val_split_idx]]).mean()\n",
    "print('Max word length: {}, average word length: {:0.1f}'.format(MAX_NUM_INPUTS, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=MAX_NUM_INPUTS, hidden_size=128, batch_first=True)\n",
    "        self.dense = nn.Linear(128 + 26, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, input_obscured_word_seen, input_letters_guessed_previously):\n",
    "        lstm_out, _ = self.lstm(input_obscured_word_seen)\n",
    "        final_lstm_output = lstm_out[:, -1, :]\n",
    "        combined_input = torch.cat((final_lstm_output, input_letters_guessed_previously), dim=1)\n",
    "        output = self.dense(combined_input)\n",
    "        return output\n",
    "\n",
    "model = LSTMNet().to(device)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "sequence_length = 10\n",
    "learning_rate = 0.001\n",
    "step_size = 1\n",
    "gamma = 0.92\n",
    "\n",
    "input_obscured_word_seen = torch.randn(BATCH_SIZE, 10, MAX_NUM_INPUTS).to(device)\n",
    "input_letters_guessed_previously = torch.randn(BATCH_SIZE, 26).to(device)\n",
    "\n",
    "output = model(input_obscured_word_seen, input_letters_guessed_previously)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "def train_model(data_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        with tqdm(total=len(data_loader), desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch') as pbar:\n",
    "            for inputs, correct_responses in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                correct_responses = correct_responses.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(*inputs)\n",
    "                loss = loss_function(outputs, correct_responses)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == correct_responses).sum().item()\n",
    "\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        classification_error = 1 - (correct_predictions / len(data_loader.dataset))\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}, Classification Error: {classification_error:.4f}')\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    progress_bar = tqdm(total=len(words), desc=f'Epoch {epoch + 1}/{NUM_EPOCHS}', unit='sample')\n",
    "\n",
    "    while total_samples < (epoch + 1) * EPOCH_SIZE:\n",
    "        if i >= len(words):\n",
    "            break\n",
    "\n",
    "        word = words[i]\n",
    "        i += 1\n",
    "\n",
    "        other_player = HangmanPlayer(word, model)\n",
    "        words_seen, previous_letters, correct_responses = other_player.run()\n",
    "\n",
    "        words_seen = torch.tensor(words_seen, dtype=torch.float32).to(device)\n",
    "        previous_letters = torch.tensor(previous_letters, dtype=torch.float32).to(device)\n",
    "        correct_responses = torch.tensor(correct_responses, dtype=torch.float32).to(device)\n",
    "\n",
    "        inputs = (words_seen, previous_letters)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)\n",
    "        loss = loss_function(outputs, correct_responses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_samples += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    progress_bar.close()\n",
    "    print(f'Epoch {epoch + 1} completed. Total Samples: {total_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_model.pth')\n",
    "print('Model saved to lstm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(my_words, my_model):\n",
    "    results = []\n",
    "\n",
    "    for word in tqdm(my_words, desc=\"Evaluating Words\"):\n",
    "        my_player = HangmanPlayer(word, my_model)\n",
    "        _ = my_player.run()\n",
    "        results.append(my_player.evaluate_performance())\n",
    "\n",
    "    df = pd.DataFrame(results, columns=['won', 'num_correct', 'num_incorrect', 'letters'])\n",
    "    return df\n",
    "\n",
    "result_df = evaluate_model(words[train_val_split_idx:], model)\n",
    "\n",
    "print('Performance on the validation set:')\n",
    "print('- Averaged {:0.1f} correct and {:0.1f} incorrect guesses per game'.format(result_df['num_correct'].mean(),\n",
    "                                                                       result_df['num_incorrect'].mean()))\n",
    "print('- Won {:0.1f}% of games played'.format(100 * result_df['won'].sum() / len(result_df.index)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
